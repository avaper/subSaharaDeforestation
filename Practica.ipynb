{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de Sistemas de Bases de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fichero necesario \"deforestationSubSahara.csv\" y éste notebook de jupyter \"Practica.ipynb\" deben encontrarse en el mismo directorio. Para que funcione correctamente se debe abrir un terminal en ese directorio o navegar hasta él desde un terminal y lanzar el comando /home/cloudera/anaconda2/bin/jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El primer ejercicio consiste en crear una tabla interna o externa para almacenar los datos. Se debe justificar la elección.\n",
    "\n",
    "Se ha elegido crear una interna, ya que pese a no aprovechar las ventajas que ofrece una tabla externa (no se elimina al subir los datos, se puede integrar mejor en el entorno de aplicaciones de Hive, se pueden cambiar dinámicamente los datos...), se garantiza la integridad de los datos y no se persigue más que un ejemplo sencillo para ésta práctica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero crearemos una carpeta donde meter los archivos que se generen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloudera/Desktop/Practica\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 556\r\n",
      "-rwxrwx--- 1 cloudera cloudera 547153 Jul  2 01:19 deforestationSubSahara.csv\r\n",
      "-rwxrwx--- 1 cloudera cloudera  17331 Oct 29 23:47 Practica.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! mkdir -p Ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, crearemos la carpeta para el usuario local en HDFS. Luego crearemos un fichero de texto con las órdenes de creación de una nueva base de datos. Para ello utilizaremos la directiva %%writefile nombreFichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir -p hadoopFicheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "drwxr-xr-x   - cloudera cloudera          0 2019-10-29 23:49 hadoopFicheros\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! mkdir -p Ficheros/DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Ficheros/DB/deforestacionDB.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile Ficheros/DB/deforestacionDB.hql\n",
    "create database if not exists deforestacion\n",
    "Comment 'Base de datos de deforestación'\n",
    "Location '/user/$(whoami)/hadoopFicheros/deforestacion'\n",
    "With dbproperties ('Creada por' = 'User', 'Creada el' = '29-Oct-2019');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar el código del fichero de arriba, utilizamos la siguiente orden, prestando atención al símbolo ! del principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "ciondbc:hive2://localhost:10000/default> create database if not exists deforesta \n",
      "' . . . . . . . . . . . . . . . . . . .> Comment 'Base de datos de deforestación \n",
      "s/deforestacion'. . . . . . . . . . . .> Location '/user/$(whoami)/hadoopFichero \n",
      "', 'Creada el' = '29-Oc . . . . . . . .> With dbproperties ('Creada por' = 'User t-2019');\n",
      "INFO  : Compiling command(queryId=hive_20191029234949_76713971-2ebc-4779-ab6f-bfdb2abfd8ab): create database if not exists deforestacion\n",
      "Comment 'Base de datos de deforestación'\n",
      "Location '/user/$(whoami)/hadoopFicheros/deforestacion'\n",
      "With dbproperties ('Creada por' = 'User', 'Creada el' = '29-Oct-2019')\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029234949_76713971-2ebc-4779-ab6f-bfdb2abfd8ab); Time taken: 0.1 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029234949_76713971-2ebc-4779-ab6f-bfdb2abfd8ab): create database if not exists deforestacion\n",
      "Comment 'Base de datos de deforestación'\n",
      "Location '/user/$(whoami)/hadoopFicheros/deforestacion'\n",
      "With dbproperties ('Creada por' = 'User', 'Creada el' = '29-Oct-2019')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029234949_76713971-2ebc-4779-ab6f-bfdb2abfd8ab); Time taken: 0.1 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.321 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -f Ficheros/DB/deforestacionDB.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras crear la base de datos, ahora crearemos una tabla en ella. \n",
    "\n",
    "La separación de los campos es \",\", y existen algunos campos compuestos, como \"Ongwam Blk I, II, and III\", motivo por el que se utilizan las líneas referentes a Serde. Ésta solución se ha consultado en el manual de Hive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Ficheros/DB/deforestacionDB.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile Ficheros/DB/deforestacionDB.hql\n",
    "use deforestacion;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS deforestacion\n",
    "(\n",
    "WorldBankRegion string, \n",
    "    country string, \n",
    "    iso3 string, \n",
    "    wdpaId string, \n",
    "    parkName string, \n",
    "    year string, \n",
    "    outsideDeforestation string, \n",
    "    insideDeforestation string\n",
    ")\n",
    "COMMENT 'Tabla de deforestación'\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES(\n",
    "    \"separatorChar\" = \",\",\n",
    "    \"quoteChar\"     = \"\\\"\"\n",
    ")\n",
    "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat'\n",
    "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "TBLPROPERTIES('skip.header.line.count'='1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecutamos el fichero anterior con la orden de abajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "0: jdbc:hive2://localhost:10000/default> use deforestacion;\n",
      "INFO  : Compiling command(queryId=hive_20191029235050_2a3f6e43-dc6a-4d2d-9e9d-80305a33fb3f): use deforestacion\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235050_2a3f6e43-dc6a-4d2d-9e9d-80305a33fb3f); Time taken: 0.1 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235050_2a3f6e43-dc6a-4d2d-9e9d-80305a33fb3f): use deforestacion\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235050_2a3f6e43-dc6a-4d2d-9e9d-80305a33fb3f); Time taken: 0.009 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.215 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "n: jdbc:hive2://localhost:10000/default> CREATE TABLE IF NOT EXISTS deforestacio \n",
      ". . . . . . . . . . . . . . . . . . . .> (\n",
      ". . . . . . . . . . . . . . . . . . . .> WorldBankRegion string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     country string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     iso3 string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     wdpaId string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     parkName string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     year string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     outsideDeforestation string, \n",
      ". . . . . . . . . . . . . . . . . . . .>     insideDeforestation string\n",
      ". . . . . . . . . . . . . . . . . . . .> )\n",
      ". . . . . . . . . . . . . . . . . . . .> COMMENT 'Tabla de deforestación'\n",
      "e.serde2.O. . . . . . . . . . . . . . .> ROW FORMAT SERDE 'org.apache.hadoop.hiv penCSVSerde'\n",
      ". . . . . . . . . . . . . . . . . . . .> WITH SERDEPROPERTIES(\n",
      ". . . . . . . . . . . . . . . . . . . .>     \"separatorChar\" = \",\",\n",
      ". . . . . . . . . . . . . . . . . . . .>     \"quoteChar\"     = \"\\\"\"\n",
      ". . . . . . . . . . . . . . . . . . . .> )\n",
      "p.mapred.TextInputFormat' . . . . . . .> STORED AS INPUTFORMAT 'org.apache.hadoo \n",
      ".io.HiveIgnoreKeyTextOutputFormat'. . .> OUTPUTFORMAT 'org.apache.hadoop.hive.ql \n",
      "'1'); . . . . . . . . . . . . . . . . .> TBLPROPERTIES('skip.header.line.count'= \n",
      "INFO  : Compiling command(queryId=hive_20191029235050_69fb665f-84e0-4796-a816-8a4443d42f7c): CREATE TABLE IF NOT EXISTS deforestacion\n",
      "(\n",
      "WorldBankRegion string,\n",
      "country string,\n",
      "iso3 string,\n",
      "wdpaId string,\n",
      "parkName string,\n",
      "year string,\n",
      "outsideDeforestation string,\n",
      "insideDeforestation string\n",
      ")\n",
      "COMMENT 'Tabla de deforestación'\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
      "WITH SERDEPROPERTIES(\n",
      "\"separatorChar\" = \",\",\n",
      "\"quoteChar\"     = \"\\\"\"\n",
      ")\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "TBLPROPERTIES('skip.header.line.count'='1')\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235050_69fb665f-84e0-4796-a816-8a4443d42f7c); Time taken: 0.023 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235050_69fb665f-84e0-4796-a816-8a4443d42f7c): CREATE TABLE IF NOT EXISTS deforestacion\n",
      "(\n",
      "WorldBankRegion string,\n",
      "country string,\n",
      "iso3 string,\n",
      "wdpaId string,\n",
      "parkName string,\n",
      "year string,\n",
      "outsideDeforestation string,\n",
      "insideDeforestation string\n",
      ")\n",
      "COMMENT 'Tabla de deforestación'\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
      "WITH SERDEPROPERTIES(\n",
      "\"separatorChar\" = \",\",\n",
      "\"quoteChar\"     = \"\\\"\"\n",
      ")\n",
      "STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat'\n",
      "OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
      "TBLPROPERTIES('skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235050_69fb665f-84e0-4796-a816-8a4443d42f7c); Time taken: 0.18 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.233 seconds)\n",
      "0: jdbc:hive2://localhost:10000/default> \n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -f Ficheros/DB/deforestacionDB.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar que efectivamente se ha creado esta tabla. Podemos ejecutar órdenes directamente sobre Hive (sin necesidad de escribirlos en un archivo) con el parámetro -e como se indica abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235050_313a5d0b-e5aa-4827-b966-84675a4e8ac6): use deforestacion\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235050_313a5d0b-e5aa-4827-b966-84675a4e8ac6); Time taken: 0.092 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235050_313a5d0b-e5aa-4827-b966-84675a4e8ac6): use deforestacion\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235050_313a5d0b-e5aa-4827-b966-84675a4e8ac6); Time taken: 0.011 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.2 seconds)\n",
      "INFO  : Compiling command(queryId=hive_20191029235050_d61932a1-ffd5-4de5-a111-058d9ef5ab39): show tables\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235050_d61932a1-ffd5-4de5-a111-058d9ef5ab39); Time taken: 0.004 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235050_d61932a1-ffd5-4de5-a111-058d9ef5ab39): show tables\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235050_d61932a1-ffd5-4de5-a111-058d9ef5ab39); Time taken: 0.013 seconds\n",
      "INFO  : OK\n",
      "+----------------+--+\n",
      "|    tab_name    |\n",
      "+----------------+--+\n",
      "| deforestacion  |\n",
      "+----------------+--+\n",
      "1 row selected (0.13 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \"use deforestacion; show tables;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El segundo ejercicio  consiste en cargar los datos da la base de datos de deforestación en la tabla creada en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos unas carpetas en HDFS y cargaremos el archivo de deforestacion en dicha carpeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir -p hadoopFicheros/datospractica\n",
    "! hadoop fs -put deforestationSubSahara.csv hadoopFicheros/datospractica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   1 cloudera cloudera     547153 2019-10-29 23:50 hadoopFicheros/datospractica/deforestationSubSahara.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls hadoopFicheros/datospractica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargaremos los datos que ya estaban en HDFS en la tabla de deforestación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235050_cba9f1bc-d763-4087-a527-9e799bfa01a1): LOAD DATA INPATH '/user/cloudera/hadoopFicheros/datospractica/deforestationSubSahara.csv' INTO TABLE deforestacion\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235050_cba9f1bc-d763-4087-a527-9e799bfa01a1); Time taken: 0.137 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235050_cba9f1bc-d763-4087-a527-9e799bfa01a1): LOAD DATA INPATH '/user/cloudera/hadoopFicheros/datospractica/deforestationSubSahara.csv' INTO TABLE deforestacion\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table deforestacion.deforestacion from hdfs://quickstart.cloudera:8020/user/cloudera/hadoopFicheros/datospractica/deforestationSubSahara.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Table deforestacion.deforestacion stats: [numFiles=1, totalSize=547153]\n",
      "INFO  : Completed executing command(queryId=hive_20191029235050_cba9f1bc-d763-4087-a527-9e799bfa01a1); Time taken: 0.224 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.458 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \\\n",
    "\"LOAD DATA INPATH '/user/$(whoami)/hadoopFicheros/datospractica/deforestationSubSahara.csv' INTO TABLE deforestacion;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comprobamos que los datos se han introducido correctamente ejecutando una orden select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235151_e9c06a5a-4930-4bc1-be37-bc286c3ec933): select * from deforestacion limit 10\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:deforestacion.worldbankregion, type:string, comment:null), FieldSchema(name:deforestacion.country, type:string, comment:null), FieldSchema(name:deforestacion.iso3, type:string, comment:null), FieldSchema(name:deforestacion.wdpaid, type:string, comment:null), FieldSchema(name:deforestacion.parkname, type:string, comment:null), FieldSchema(name:deforestacion.year, type:string, comment:null), FieldSchema(name:deforestacion.outsidedeforestation, type:string, comment:null), FieldSchema(name:deforestacion.insidedeforestation, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235151_e9c06a5a-4930-4bc1-be37-bc286c3ec933); Time taken: 0.144 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235151_e9c06a5a-4930-4bc1-be37-bc286c3ec933): select * from deforestacion limit 10\n",
      "INFO  : Completed executing command(queryId=hive_20191029235151_e9c06a5a-4930-4bc1-be37-bc286c3ec933); Time taken: 0.003 seconds\n",
      "INFO  : OK\n",
      "+--------------------------------+------------------------+---------------------+-----------------------+-------------------------+---------------------+-------------------------------------+------------------------------------+--+\n",
      "| deforestacion.worldbankregion  | deforestacion.country  | deforestacion.iso3  | deforestacion.wdpaid  | deforestacion.parkname  | deforestacion.year  | deforestacion.outsidedeforestation  | deforestacion.insidedeforestation  |\n",
      "+--------------------------------+------------------------+---------------------+-----------------------+-------------------------+---------------------+-------------------------------------+------------------------------------+--+\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2001                | 18.2                                | 3.88                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2002                | 6.51                                | 1.41                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2003                | 19.29                               | 11.5                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2004                | 7.96                                | 2.45                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2005                | 15.55                               | 6.29                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2006                | 5.15                                | 2.26                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2007                | 22.28                               | 5.49                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2008                | 18.67                               | 8.3                                |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2009                | 7.46                                | 6.12                               |\n",
      "| Sub-Saharan Africa             | Burundi                | BDI                 | 9161                  | Kibira                  | 2010                | 16.98                               | 11.38                              |\n",
      "+--------------------------------+------------------------+---------------------+-----------------------+-------------------------+---------------------+-------------------------------------+------------------------------------+--+\n",
      "10 rows selected (0.41 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \"select * from deforestacion limit 10;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El tercer ejercicio consiste en crear una vista con los campos iso3, wdpa-id, nombre del parque, porcentaje de deforestación interna, y porcentaje de deforestación externa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la vista será suficiente con la siguiente instrucción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235151_bc59a3f5-9fde-4b38-893b-fdb778b732af): create view vista as select  iso3, wdpaid, parkname, outsidedeforestation, insidedeforestation from deforestacion\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:iso3, type:string, comment:null), FieldSchema(name:wdpaid, type:string, comment:null), FieldSchema(name:parkname, type:string, comment:null), FieldSchema(name:outsidedeforestation, type:string, comment:null), FieldSchema(name:insidedeforestation, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235151_bc59a3f5-9fde-4b38-893b-fdb778b732af); Time taken: 0.126 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235151_bc59a3f5-9fde-4b38-893b-fdb778b732af): create view vista as select  iso3, wdpaid, parkname, outsidedeforestation, insidedeforestation from deforestacion\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235151_bc59a3f5-9fde-4b38-893b-fdb778b732af); Time taken: 0.04 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.259 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \\\n",
    "\"create view vista as select  iso3, wdpaid, parkname, outsidedeforestation, insidedeforestation from deforestacion;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El cuarto ejercicio consiste en realizar 3 consultas a la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apartado 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta para obtener el porcentaje de deforestación interno del parque Rusizi en el año 2011:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235151_e3e8fff0-98bf-4bbe-87c9-555f8a35867e): select insidedeforestation from deforestacion where year='2011' and parkname='Rusizi'\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:insidedeforestation, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235151_e3e8fff0-98bf-4bbe-87c9-555f8a35867e); Time taken: 0.155 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235151_e3e8fff0-98bf-4bbe-87c9-555f8a35867e): select insidedeforestation from deforestacion where year='2011' and parkname='Rusizi'\n",
      "INFO  : Completed executing command(queryId=hive_20191029235151_e3e8fff0-98bf-4bbe-87c9-555f8a35867e); Time taken: 0.001 seconds\n",
      "INFO  : OK\n",
      "+----------------------+--+\n",
      "| insidedeforestation  |\n",
      "+----------------------+--+\n",
      "| 27.43                |\n",
      "+----------------------+--+\n",
      "1 row selected (0.45 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \\\n",
    "\"select insidedeforestation from deforestacion where year='2011' and parkname='Rusizi';\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apartado 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta para obtener los 10 parques con mayor porcentaje medio de deforestación interno (se realiza sobre la vista creada en el ejercicio 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 4ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235252_650cd279-18b6-4b66-ac66-19dac1e09b80): select parkname, avg(insidedeforestation) as media from vista group by parkname order by media desc limit 10\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:parkname, type:string, comment:null), FieldSchema(name:media, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235252_650cd279-18b6-4b66-ac66-19dac1e09b80); Time taken: 0.212 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235252_650cd279-18b6-4b66-ac66-19dac1e09b80): select parkname, avg(insidedeforestation) as media from vista group by parkname order by media desc limit 10\n",
      "INFO  : Query ID = hive_20191029235252_650cd279-18b6-4b66-ac66-19dac1e09b80\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1572393120588_0028, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1572393120588_0028/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1572393120588_0028\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-10-29 23:52:27,420 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-10-29 23:52:41,151 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.76 sec\n",
      "INFO  : 2019-10-29 23:52:56,984 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.1 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 100 msec\n",
      "INFO  : Ended Job = job_1572393120588_0028\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1572393120588_0029, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1572393120588_0029/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1572393120588_0029\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-10-29 23:53:12,634 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-10-29 23:53:24,952 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec\n",
      "INFO  : 2019-10-29 23:53:42,934 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.4 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 4 seconds 400 msec\n",
      "INFO  : Ended Job = job_1572393120588_0029\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.1 sec   HDFS Read: 554181 HDFS Write: 26023 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.4 sec   HDFS Read: 31139 HDFS Write: 272 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 9 seconds 500 msec\n",
      "INFO  : Completed executing command(queryId=hive_20191029235252_650cd279-18b6-4b66-ac66-19dac1e09b80); Time taken: 92.183 seconds\n",
      "INFO  : OK\n",
      "+-------------------------+--------------------+--+\n",
      "|        parkname         |       media        |\n",
      "+-------------------------+--------------------+--+\n",
      "| Ora-Iuleha-Ozalla       | 92.68666666666667  |\n",
      "| Okeluse                 | 88.77416666666666  |\n",
      "| Eastern Mau             | 85.7625            |\n",
      "| Mafuga                  | 85.22666666666667  |\n",
      "| Sao Hill                | 85.07833333333333  |\n",
      "| Okavu - Reru            | 82.80749999999999  |\n",
      "| Desiri                  | 81.62833333333333  |\n",
      "| Gulosilo                | 80.52166666666666  |\n",
      "| Ogbesse                 | 79.04              |\n",
      "| Asufu Shelterbelt East  | 78.48083333333334  |\n",
      "+-------------------------+--------------------+--+\n",
      "10 rows selected (92.623 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \\\n",
    "\"select parkname, avg(insidedeforestation) as media from vista group by parkname order by media desc limit 10;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apartado 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta para obtener los 10 países con mayor porcentaje medio de deforestación en el año 2012:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235454_abeb8ea2-26ff-43be-b86c-6261072ae151): select country, sum(insidedeforestation) as total from deforestacion where year='2012' group by country order by total desc limit 10\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:country, type:string, comment:null), FieldSchema(name:total, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235454_abeb8ea2-26ff-43be-b86c-6261072ae151); Time taken: 0.291 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235454_abeb8ea2-26ff-43be-b86c-6261072ae151): select country, sum(insidedeforestation) as total from deforestacion where year='2012' group by country order by total desc limit 10\n",
      "INFO  : Query ID = hive_20191029235454_abeb8ea2-26ff-43be-b86c-6261072ae151\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1572393120588_0030, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1572393120588_0030/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1572393120588_0030\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-10-29 23:54:18,207 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-10-29 23:54:31,991 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.94 sec\n",
      "INFO  : 2019-10-29 23:54:47,898 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.38 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 380 msec\n",
      "INFO  : Ended Job = job_1572393120588_0030\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : Starting Job = job_1572393120588_0031, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1572393120588_0031/\n",
      "INFO  : Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1572393120588_0031\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2019-10-29 23:55:05,844 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2019-10-29 23:55:19,424 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.61 sec\n",
      "INFO  : 2019-10-29 23:55:34,355 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.95 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 950 msec\n",
      "INFO  : Ended Job = job_1572393120588_0031\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.38 sec   HDFS Read: 555091 HDFS Write: 739 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.95 sec   HDFS Read: 5851 HDFS Write: 252 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 9 seconds 330 msec\n",
      "INFO  : Completed executing command(queryId=hive_20191029235454_abeb8ea2-26ff-43be-b86c-6261072ae151); Time taken: 91.754 seconds\n",
      "INFO  : OK\n",
      "+---------------------------+---------------------+--+\n",
      "|          country          |        total        |\n",
      "+---------------------------+---------------------+--+\n",
      "| Nigeria                   | 2721.5999999999985  |\n",
      "| Ghana                     | 2277.010000000001   |\n",
      "| Kenya                     | 1241.2099999999998  |\n",
      "| Uganda                    | 843.69              |\n",
      "| Tanzania                  | 692.8100000000002   |\n",
      "| Madagascar                | 381.52              |\n",
      "| Guinea                    | 262.46              |\n",
      "| Cameroon                  | 212.84000000000003  |\n",
      "| Central African Republic  | 147.87000000000003  |\n",
      "| Sierra Leone              | 83.61000000000001   |\n",
      "+---------------------------+---------------------+--+\n",
      "10 rows selected (92.411 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \\\n",
    "\"select country, sum(insidedeforestation) as total from deforestacion where year='2012' group by country order by total desc limit 10;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El quinto ejercicio consiste en desarrollar un código MapReduce en Python que implemente la consulta del apartado 1 del ejercicio 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean las carpetas necesarias y el mapper, ya que en éste caso no es necesario un reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! mkdir -p Ficheros/MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwxr-x 2 cloudera cloudera 4096 Oct 29 23:49 DB\r\n",
      "drwxrwxr-x 2 cloudera cloudera 4096 Oct 29 23:55 MAPPER\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l Ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código mapper.py es el siguiente. En él no se han considerado los campos compuestos, ya que se conoce de antemano la respuesta al haber efectuado la misma consulta en el apartado 1 del ejercicio 4 y haber comprobado que funciona correctamente, ya que el campo solucitado no es compuesto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Ficheros/MAPPER/mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Ficheros/MAPPER/mapper.py\n",
    "#!/usr/bin/python\n",
    " \n",
    "import sys\n",
    "\n",
    "# Recorremos la entrada \n",
    "for line in sys.stdin:\n",
    "    \n",
    "    # Separamos por comas\n",
    "    data = line.strip().split(\",\")\n",
    "\n",
    "    # Filtramos las lineas por numero de columnas\n",
    "    if len(data) == 8:\n",
    "        \n",
    "        # Obtenemos los datos\n",
    "        WorldBankRegion, country, iso3, wdpaId, parkName, year, outsideDeforestation, insideDeforestation = data\n",
    "    \n",
    "    # Filtramos con las condiciones del apartado 1 del ejercicio 4\n",
    "    if year==\"2011\" and parkName==\"Rusizi\":\n",
    "\n",
    "        # Las imprimimos\n",
    "        print \"{0}\".format(outsideDeforestation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "-rw-rw-r-- 1 cloudera cloudera 562 Oct 29 23:55 mapper.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l Ficheros/MAPPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobaremos que el código map funciona correctamente con el código de abajo, que simula localmente la ejecución MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! cat deforestationSubSahara.csv | python Ficheros/MAPPER/mapper.py > Ficheros/MAPPER/salidamapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "-rw-rw-r-- 1 cloudera cloudera 562 Oct 29 23:55 mapper.py\r\n",
      "-rw-rw-r-- 1 cloudera cloudera   6 Oct 29 23:55 salidamapper\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l Ficheros/MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.36\r\n"
     ]
    }
   ],
   "source": [
    "! cat Ficheros/MAPPER/salidamapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probaremos el código en Hadoop. Para ello lo primero tendremos que cargar el fichero de texto en HDFS, y tras eso, podremos ejecutar nuestro código MapReduce en Hadoop. Al hacer esto, estaremos utilizando toda la potencia de nuestro cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -mkdir -p hadoopFicheros/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put deforestationSubSahara.csv hadoopFicheros/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   1 cloudera cloudera     547153 2019-10-29 23:56 hadoopFicheros/tmp/deforestationSubSahara.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls hadoopFicheros/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/10/29 23:56:17 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [Ficheros/MAPPER/mapper.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.12.0.jar] /tmp/streamjob2583890420813175416.jar tmpDir=null\n",
      "19/10/29 23:56:21 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/10/29 23:56:22 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/10/29 23:56:23 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "19/10/29 23:56:23 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "19/10/29 23:56:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1572393120588_0032\n",
      "19/10/29 23:56:24 INFO impl.YarnClientImpl: Submitted application application_1572393120588_0032\n",
      "19/10/29 23:56:24 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1572393120588_0032/\n",
      "19/10/29 23:56:24 INFO mapreduce.Job: Running job: job_1572393120588_0032\n",
      "19/10/29 23:56:37 INFO mapreduce.Job: Job job_1572393120588_0032 running in uber mode : false\n",
      "19/10/29 23:56:37 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "19/10/29 23:56:58 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "19/10/29 23:57:00 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "19/10/29 23:57:11 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/10/29 23:57:11 INFO mapreduce.Job: Job job_1572393120588_0032 completed successfully\n",
      "19/10/29 23:57:11 INFO mapreduce.Job: Counters: 50\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15\n",
      "\t\tFILE: Number of bytes written=382871\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=551535\n",
      "\t\tHDFS: Number of bytes written=7\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=37897\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=10638\n",
      "\t\tTotal time spent by all map tasks (ms)=37897\n",
      "\t\tTotal time spent by all reduce tasks (ms)=10638\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=37897\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=10638\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=38806528\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=10893312\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=8521\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=7\n",
      "\t\tMap output materialized bytes=21\n",
      "\t\tInput split bytes=286\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=21\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=771\n",
      "\t\tCPU time spent (ms)=3880\n",
      "\t\tPhysical memory (bytes) snapshot=558419968\n",
      "\t\tVirtual memory (bytes) snapshot=4523950080\n",
      "\t\tTotal committed heap usage (bytes)=391979008\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=551249\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=7\n",
      "19/10/29 23:57:11 INFO streaming.StreamJob: Output directory: hadoopFicheros/tmp/salida-mapper\n"
     ]
    }
   ],
   "source": [
    "! hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -file Ficheros/MAPPER/mapper.py \\\n",
    "-mapper Ficheros/MAPPER/mapper.py -input hadoopFicheros/tmp/deforestationSubSahara.csv \\\n",
    "-output hadoopFicheros/tmp/salida-mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 cloudera cloudera          0 2019-10-29 23:57 hadoopFicheros/tmp/salida-mapper/_SUCCESS\r\n",
      "-rw-r--r--   1 cloudera cloudera          7 2019-10-29 23:57 hadoopFicheros/tmp/salida-mapper/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls hadoopFicheros/tmp/salida-mapper/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.36\t\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -cat hadoopFicheros/tmp/salida-mapper/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 2ms\n",
      "Connecting to jdbc:hive2://localhost:10000/deforestacion\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235757_aa7b860e-7253-4e98-80b3-3cd96754a6d5): drop database deforestacion cascade\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235757_aa7b860e-7253-4e98-80b3-3cd96754a6d5); Time taken: 0.238 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235757_aa7b860e-7253-4e98-80b3-3cd96754a6d5): drop database deforestacion cascade\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235757_aa7b860e-7253-4e98-80b3-3cd96754a6d5); Time taken: 0.31 seconds\n",
      "INFO  : OK\n",
      "No rows affected (0.663 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/deforestacion\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/deforestacion\" -e \"drop database deforestacion cascade;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan complete in 3ms\n",
      "Connecting to jdbc:hive2://localhost:10000/default\n",
      "Connected to: Apache Hive (version 1.1.0-cdh5.12.0)\n",
      "Driver: Hive JDBC (version 1.1.0-cdh5.12.0)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=hive_20191029235858_f55a045d-b077-4a6d-b71c-c75051c343b3): show tables\n",
      "INFO  : Semantic Analysis Completed\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=hive_20191029235858_f55a045d-b077-4a6d-b71c-c75051c343b3); Time taken: 0.097 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=hive_20191029235858_f55a045d-b077-4a6d-b71c-c75051c343b3): show tables\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=hive_20191029235858_f55a045d-b077-4a6d-b71c-c75051c343b3); Time taken: 0.031 seconds\n",
      "INFO  : OK\n",
      "+-----------+--+\n",
      "| tab_name  |\n",
      "+-----------+--+\n",
      "+-----------+--+\n",
      "No rows selected (0.283 seconds)\n",
      "Beeline version 1.1.0-cdh5.12.0 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/default\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/default\" -e \"show tables;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hadoop fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted hadoopFicheros\r\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -rm -r hadoopFicheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! hadoop fs -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras la limpieza, todavía quedará el directorio /user/$(whoami) que crea Hive al insertar la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Ficheros locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -r Ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 588\r\n",
      "-rwxrwx--- 1 cloudera cloudera 547153 Jul  2 01:19 deforestationSubSahara.csv\r\n",
      "-rwxrwx--- 1 cloudera cloudera  52849 Oct 29 23:56 Practica.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
